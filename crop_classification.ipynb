{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2qNGWNRYG7Mjo8jM/eLM5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabriel-git24/Crop_classification/blob/main/crop_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-ZKQRtF84cF"
      },
      "outputs": [],
      "source": [
        "# working on a machine lerning algorithm, that will classify or determine which crop to grow when a set of specific parameters are put down using streamlit\n",
        "'''\n",
        "Decision Trees - easy to learn, best for tabular data\n",
        "RandomForest\n",
        "Logistic Regression\n",
        "Linear Regression\n",
        "*** bonus _ XGBoost\n",
        "Unsupervised learning\n",
        "  K-means clustering (market segmentation)\n",
        "  DBSCAN clustering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "sQlOlNsS9IYa",
        "outputId": "f514a365-f705-45e6-c50b-da09e947f8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = '/content/drive/MyDrive/Crop_recommendation.csv'\n",
        "\n",
        "import pandas as pd\n",
        "# pd.set_option('display.max_rows', None)\n",
        "# pd.set_option('display.max_columns', None)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "JyPOj3vJ9b13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data)\n",
        "\n",
        "df.head(5)\n",
        "# display(df.info())"
      ],
      "metadata": {
        "id": "OQeYGL2X9wiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = df['label'].unique()\n",
        "label_list = label_list.tolist()\n",
        "\n",
        "for crop in label_list:\n",
        "  counts = (df['label'] == crop).sum()\n",
        "  print(f'{crop}:',str(counts))"
      ],
      "metadata": {
        "id": "d0rxOAY093_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['temperature'].describe().round(2)"
      ],
      "metadata": {
        "id": "DivI1I9SRY4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['humidity'].describe().round(2)"
      ],
      "metadata": {
        "id": "iQvRIo06e-u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['ph'].describe().round(2)"
      ],
      "metadata": {
        "id": "zOQ5hTwDkM2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['rainfall'].describe().round(2)"
      ],
      "metadata": {
        "id": "jYoCm_q1kVzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_summary_crop(crop):\n",
        "  crop_df = df[df['label'] == crop]\n",
        "  x = crop_df.describe().round(2)\n",
        "  selected_stats = x.loc[['mean', 'std', 'min', '50%', 'max']]\n",
        "  return selected_stats\n",
        "\n",
        "for crop in label_list:\n",
        "  summary = create_summary_crop(crop)\n",
        "  print('\\n')\n",
        "  print(f'Summary statistics for {crop.capitalize()}')\n",
        "  display(summary)"
      ],
      "metadata": {
        "id": "NiSORAXRkcNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# labeling rice as 1 and others as 0\n",
        "\n",
        "def convert_to_rice(row):\n",
        "  if row == 'rice':\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "df['is_rice'] = df['label'].apply(convert_to_rice)"
      ],
      "metadata": {
        "id": "CA1fbipz23FQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting into training, validation and testing datasets (60/20/20)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
        "y = df['is_rice']\n",
        "\n",
        "X_train_main, X_test, y_train_main, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_main, y_train_main, test_size=.25, random_state=42) # 0.25 of 80 is 20"
      ],
      "metadata": {
        "id": "EoKpEF0qYjY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "vpfwbIfgYmFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "scores = cross_val_score(rf, X_val_scaled, y_val, cv=3)\n",
        "print(scores)\n",
        "\n",
        "#calculating the mean score\n",
        "mean_score = np.mean(scores)\n",
        "print(f\"Mean cross-validation score is: {mean_score:.4f}\")\n",
        "\n",
        "\n",
        "stdScore = np.std(scores)\n",
        "print(f\"Standard deviation of the score is: {stdScore:.4f}\")"
      ],
      "metadata": {
        "id": "KxC7FhjuaraZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the final model on the full training data\n",
        "\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test_scaled)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "classificationReport = classification_report(y_test, y_pred)\n",
        "print(f\"Classification Report: {classificationReport}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "display(cm)"
      ],
      "metadata": {
        "id": "QngjiZfpcFLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# param_grid = {\n",
        "#     'min_samples_leaf': [25, 50, 75, 100, 200, 300],\n",
        "#     'min_impurity_decrease': [0.0, 0.001, 0.005, 0.01, 0.015, 0.02]\n",
        "# }\n",
        "\n",
        "# tree = DecisionTreeClassifier(random_state=12345)\n",
        "\n",
        "# cv = RepeatedKFold(n_splits=10, n_repeats=10, random_state=54321)\n",
        "\n",
        "# grid_cv = GridSearchCV(tree, param_grid, scoring='accuracy', n_jobs=5, cv=cv, refit=True)\n",
        "\n",
        "# grid_cv.fit(train_X, train_y)\n",
        "\n",
        "# print(grid_cv.best_params_)\n",
        "\n",
        "\n",
        "# RepeatedKFold is probably better because the hardest data might end up in one pile but since repeatedkfold is shuffling it, you will avoid that\n",
        "\n",
        "\n",
        "# cv_results = pd.DataFrame(grid_cs.cv_results).filter(like = 'split')\n",
        "\n",
        "# best_results = cv_results.loc[grid_cv.best_index_, :]\n",
        "\n",
        "# print(f'Mean Accuracy: {best_results.mean()}')\n",
        "# print(f'Accuracy Std Deviation: {best_results.std()}')\n",
        "\n",
        "\n",
        "test_y = label_encoder.transform(adult_test['label'])\n",
        "print(label_encoder.classes_)\n",
        "best_tree = grid_cv.best_estimator_\n",
        "print(type(best_tree))\n",
        "\n",
        "best_tree.score(test_X, test_7)\n"
      ],
      "metadata": {
        "id": "cGOVSB_sFIk5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}